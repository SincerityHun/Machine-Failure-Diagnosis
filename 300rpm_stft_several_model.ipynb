{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비교 실험\n",
    "- 데이터는 가운데 5번째 1분만 사용\n",
    "1. STFT + LSTM\n",
    "2. STFT + LSTM AutoEncoder\n",
    "3. STFT + Transformer\n",
    "4. STFT + LSTM AutoEncoder + Attention\n",
    "5. STFT + Conv LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (\n",
    "    LSTM,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    "    Layer,\n",
    "    MultiHeadAttention,\n",
    "    LayerNormalization,\n",
    "    Add,\n",
    "    GlobalAveragePooling1D,\n",
    "    ConvLSTM2D,\n",
    "    BatchNormalization,\n",
    "    Attention,\n",
    "    Conv3D,\n",
    "    Reshape,\n",
    "    TimeDistributed,\n",
    "    Flatten,\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 파일 로드 및 정규화\n",
    "def normalize_data(df, features):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPM = 300\n",
    "base_path = \"5000hz_raw_data/\" + str(RPM) + \"rpm/\"\n",
    "folders = [\n",
    "    str(RPM) + \"rpm \" + \"normal data\",\n",
    "    str(RPM) + \"rpm \" + \"carriage damage\",\n",
    "    str(RPM) + \"rpm \" + \"high-speed damage\",\n",
    "    str(RPM) + \"rpm \" + \"lack of lubrication\",\n",
    "    str(RPM) + \"rpm \" + \"oxidation and corrosion\",\n",
    "]\n",
    "columns = [\"motor1_x\", \"motor1_y\", \"motor1_z\", \"sound\", \"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 읽고 결합하는 함수\n",
    "def read_and_concatenate(folder):\n",
    "    all_files = []\n",
    "    count = 4\n",
    "    for file_name in os.listdir(folder):\n",
    "        if count != 0:\n",
    "            count -= 1\n",
    "            continue\n",
    "\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder, file_name)\n",
    "            df = pd.read_csv(file_path, usecols=columns)\n",
    "            all_files.append(df)\n",
    "            \n",
    "    combined_df = pd.concat(all_files)\n",
    "    combined_df.sort_values(\"time\", inplace=True)  # 시간 열 기준 정렬\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = dict()\n",
    "folder_index = [\n",
    "    \"normal data\",\n",
    "    \"carriage damage\",\n",
    "    \"high-speed damage\",\n",
    "    \"lack of lubrication\",\n",
    "    \"oxidation and corrosion\",\n",
    "]\n",
    "# 각 폴더에서 데이터를 처리\n",
    "features = [\"motor1_x\", \"motor1_y\", \"motor1_z\", \"sound\"]\n",
    "for index, folder_name in enumerate(folders):\n",
    "    folder_path = os.path.join(base_path, folder_name)\n",
    "    concatenated_df[folder_index[index]] = read_and_concatenate(folder_path)\n",
    "    concatenated_df[folder_index[index]] = normalize_data(concatenated_df[folder_index[index]], features) # 정규화\n",
    "    # time 열 제거\n",
    "    # concatenated_df[folder_index[index]].drop(columns=\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT 수행\n",
    "fs = 5000\n",
    "def compute_stft(data):\n",
    "    return np.array(\n",
    "        [\n",
    "            np.abs(scipy.signal.stft(d, fs=fs, nperseg=min(d.shape[-1], 256))[2])\n",
    "            for d in data\n",
    "        ]\n",
    "    )  # 절대값을 사용하여 실수 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, folder_name in enumerate(folders):\n",
    "    concatenated_df[folder_index[index]] = compute_stft(\n",
    "        concatenated_df[folder_index[index]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT 데이터 합치기\n",
    "def concatenate_data(*stft_data):\n",
    "    min_time_steps = min(stft.shape[2] for stft in stft_data)\n",
    "    return np.concatenate([stft[:, :, :min_time_steps] for stft in stft_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, folder_name in enumerate(folders):\n",
    "    concatenated_df[folder_index[index]] = concatenate_data(\n",
    "        concatenated_df[folder_index[index]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X 데이터 합치기\n",
    "X = np.concatenate(\n",
    "    [concatenated_df[folder_index[index]] for index, folder_name in enumerate(folders)],\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 생성\n",
    "Y = np.concatenate(\n",
    "    (\n",
    "        np.zeros(concatenated_df[folder_index[0]].shape[0]),\n",
    "        np.ones(concatenated_df[folder_index[1]].shape[0]),\n",
    "        np.full(concatenated_df[folder_index[2]].shape[0], 2),\n",
    "        np.full(concatenated_df[folder_index[3]].shape[0], 3),\n",
    "        np.full(concatenated_df[folder_index[4]].shape[0], 4),\n",
    "    )\n",
    ")\n",
    "# 원핫 인코딩ㅇ\n",
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 (6:2:2)\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train_val, Y_train_val, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (5400000, 3, 3)\n",
      "Test data shape: (1800000, 3, 3)\n",
      "Validation data shape: (1800000, 3, 3)\n",
      "Train label shape: (1800000, 5)\n",
      "Train label shape: (5400000, 5)\n",
      "Test label shape: (1800000, 5)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 형태 확인\n",
    "# (데이터 수, 시간, 특징 수)\n",
    "print(\"Train data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Train label shape:\", Y_val.shape)\n",
    "print(\"Train label shape:\", Y_train.shape)\n",
    "print(\"Test label shape:\", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 형태 변환  (샘플 수, 시간, 특징 수)\n",
    "X_train = X_train.reshape(\n",
    "    X_train.shape[0], X_train.shape[1], -1\n",
    ")  \n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape after reshape: (5400000, 3, 3)\n",
      "Validation data shape after reshape: (1800000, 3, 3)\n",
      "Test data shape after reshape: (1800000, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "# 코드 확인\n",
    "print(\"Train data shape after reshape:\", X_train.shape)\n",
    "print(\"Validation data shape after reshape:\", X_val.shape)\n",
    "print(\"Test data shape after reshape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. STFT + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 생성\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "# LSTM Autoencoder 모델 정의\n",
    "def create_lstm(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    encoded = LSTM(128, activation=\"relu\", return_sequences=True)(inputs)\n",
    "    encoded = LSTM(64, activation=\"relu\", return_sequences=True)(encoded)\n",
    "    encoded = LSTM(32, activation=\"relu\")(encoded)\n",
    "    dense = Dense(64, activation=\"relu\")(encoded)\n",
    "    dropout = Dropout(0.2)(dense)\n",
    "    outputs = Dense(5, activation=\"softmax\")(dropout)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">67,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m67,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,845</span> (515.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131,845\u001b[0m (515.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,845</span> (515.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m131,845\u001b[0m (515.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = create_lstm(input_shape)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼리스탑 콜백 설정\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 14ms/step - accuracy: 0.2561 - loss: 1.5610 - val_accuracy: 0.3932 - val_loss: 1.2858\n",
      "Epoch 2/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 14ms/step - accuracy: 0.4325 - loss: 1.2068 - val_accuracy: 0.5899 - val_loss: 0.9349\n",
      "Epoch 3/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 14ms/step - accuracy: 0.5539 - loss: 0.9745 - val_accuracy: 0.6490 - val_loss: 0.8022\n",
      "Epoch 4/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 14ms/step - accuracy: 0.6117 - loss: 0.8600 - val_accuracy: 0.7106 - val_loss: 0.6737\n",
      "Epoch 5/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 15ms/step - accuracy: 0.6867 - loss: 0.7025 - val_accuracy: 0.8018 - val_loss: 0.4937\n",
      "Epoch 6/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 14ms/step - accuracy: 0.7373 - loss: 0.5935 - val_accuracy: 0.7966 - val_loss: 0.4797\n",
      "Epoch 7/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 14ms/step - accuracy: 0.7658 - loss: 0.5353 - val_accuracy: 0.7862 - val_loss: 0.4785\n",
      "Epoch 8/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 14ms/step - accuracy: 0.7861 - loss: 0.4943 - val_accuracy: 0.8455 - val_loss: 0.3712\n",
      "Epoch 9/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.4317 - val_accuracy: 0.8909 - val_loss: 0.2623\n",
      "Epoch 10/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 14ms/step - accuracy: 0.8342 - loss: 0.3881 - val_accuracy: 0.8563 - val_loss: 0.3473\n",
      "Epoch 11/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 14ms/step - accuracy: 0.8447 - loss: 0.3689 - val_accuracy: 0.9142 - val_loss: 0.2214\n",
      "Epoch 12/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 13ms/step - accuracy: 0.8603 - loss: 0.3305 - val_accuracy: 0.8896 - val_loss: 0.2638\n",
      "Epoch 13/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 13ms/step - accuracy: 0.8669 - loss: 0.3154 - val_accuracy: 0.7751 - val_loss: 0.5323\n",
      "Epoch 14/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 13ms/step - accuracy: 0.8745 - loss: 0.3003 - val_accuracy: 0.8985 - val_loss: 0.2497\n",
      "Epoch 15/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 13ms/step - accuracy: 0.8837 - loss: 0.2809 - val_accuracy: 0.9309 - val_loss: 0.1808\n",
      "Epoch 16/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 14ms/step - accuracy: 0.8900 - loss: 0.2668 - val_accuracy: 0.9063 - val_loss: 0.2065\n",
      "Epoch 17/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 14ms/step - accuracy: 0.8967 - loss: 0.2514 - val_accuracy: 0.9380 - val_loss: 0.1480\n",
      "Epoch 18/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 14ms/step - accuracy: 0.8999 - loss: 0.2448 - val_accuracy: 0.9349 - val_loss: 0.1526\n",
      "Epoch 19/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 14ms/step - accuracy: 0.9035 - loss: 0.2350 - val_accuracy: 0.9417 - val_loss: 0.1376\n",
      "Epoch 20/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 14ms/step - accuracy: 0.9084 - loss: 0.2249 - val_accuracy: 0.9215 - val_loss: 0.2002\n",
      "Epoch 21/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 14ms/step - accuracy: 0.9108 - loss: 0.2188 - val_accuracy: 0.9380 - val_loss: 0.1349\n",
      "Epoch 22/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 13ms/step - accuracy: 0.9132 - loss: 0.2124 - val_accuracy: 0.9407 - val_loss: 0.1341\n",
      "Epoch 23/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 13ms/step - accuracy: 0.9149 - loss: 0.2082 - val_accuracy: 0.9544 - val_loss: 0.1100\n",
      "Epoch 24/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 14ms/step - accuracy: 0.9181 - loss: 0.2016 - val_accuracy: 0.9519 - val_loss: 0.1120\n",
      "Epoch 25/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 14ms/step - accuracy: 0.9203 - loss: 0.1948 - val_accuracy: 0.9527 - val_loss: 0.1219\n",
      "Epoch 26/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 14ms/step - accuracy: 0.9223 - loss: 0.1900 - val_accuracy: 0.9429 - val_loss: 0.1390\n",
      "Epoch 27/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 14ms/step - accuracy: 0.9237 - loss: 0.1893 - val_accuracy: 0.9578 - val_loss: 0.1073\n",
      "Epoch 28/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 14ms/step - accuracy: 0.9276 - loss: 0.1803 - val_accuracy: 0.9563 - val_loss: 0.1037\n",
      "Epoch 29/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 14ms/step - accuracy: 0.9268 - loss: 0.1824 - val_accuracy: 0.9524 - val_loss: 0.1153\n",
      "Epoch 30/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 14ms/step - accuracy: 0.9304 - loss: 0.1722 - val_accuracy: 0.9544 - val_loss: 0.1101\n",
      "Epoch 31/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 14ms/step - accuracy: 0.9323 - loss: 0.1696 - val_accuracy: 0.9533 - val_loss: 0.1063\n",
      "Epoch 32/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 14ms/step - accuracy: 0.9330 - loss: 0.1665 - val_accuracy: 0.9619 - val_loss: 0.0853\n",
      "Epoch 33/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 14ms/step - accuracy: 0.9342 - loss: 0.1645 - val_accuracy: 0.9432 - val_loss: 0.1470\n",
      "Epoch 34/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 14ms/step - accuracy: 0.9359 - loss: 0.1689 - val_accuracy: 0.9563 - val_loss: 0.1033\n",
      "Epoch 35/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 14ms/step - accuracy: 0.9379 - loss: 0.1560 - val_accuracy: 0.9656 - val_loss: 0.0787\n",
      "Epoch 36/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 14ms/step - accuracy: 0.9382 - loss: 0.1551 - val_accuracy: 0.9547 - val_loss: 0.1047\n",
      "Epoch 37/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 14ms/step - accuracy: 0.9391 - loss: 0.1539 - val_accuracy: 0.9469 - val_loss: 0.1238\n",
      "Epoch 38/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 14ms/step - accuracy: 0.9259 - loss: 0.2037 - val_accuracy: 0.9598 - val_loss: 0.0908\n",
      "Epoch 39/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 14ms/step - accuracy: 0.9414 - loss: 0.1470 - val_accuracy: 0.9625 - val_loss: 0.0874\n",
      "Epoch 40/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 14ms/step - accuracy: 0.9432 - loss: 0.1431 - val_accuracy: 0.9524 - val_loss: 0.1122\n",
      "Epoch 41/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 14ms/step - accuracy: 0.9430 - loss: 0.1440 - val_accuracy: 0.9510 - val_loss: 0.1141\n",
      "Epoch 42/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 14ms/step - accuracy: 0.9453 - loss: 0.1385 - val_accuracy: 0.9655 - val_loss: 0.0891\n",
      "Epoch 43/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 13ms/step - accuracy: 0.9438 - loss: 0.1588 - val_accuracy: 0.9527 - val_loss: 0.1095\n",
      "Epoch 44/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 13ms/step - accuracy: 0.9483 - loss: 0.1296 - val_accuracy: 0.9686 - val_loss: 0.0740\n",
      "Epoch 45/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 14ms/step - accuracy: 0.9468 - loss: 0.1351 - val_accuracy: 0.9354 - val_loss: 0.1383\n",
      "Epoch 46/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 14ms/step - accuracy: 0.9497 - loss: 0.1263 - val_accuracy: 0.9714 - val_loss: 0.0653\n",
      "Epoch 47/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 14ms/step - accuracy: 0.9505 - loss: 0.1242 - val_accuracy: 0.9727 - val_loss: 0.0639\n",
      "Epoch 48/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 14ms/step - accuracy: 0.9515 - loss: 0.1218 - val_accuracy: 0.9451 - val_loss: 0.1318\n",
      "Epoch 49/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4321s\u001b[0m 205ms/step - accuracy: 0.9497 - loss: 0.1289 - val_accuracy: 0.9645 - val_loss: 0.0844\n",
      "Epoch 50/100\n",
      "\u001b[1m21094/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4211s\u001b[0m 200ms/step - accuracy: 0.9527 - loss: 0.1196 - val_accuracy: 0.8711 - val_loss: 0.4572\n",
      "Epoch 51/100\n",
      "\u001b[1m20655/21094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:06\u001b[0m 152ms/step - accuracy: 0.9533 - loss: 0.1172"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT + LSTM 모델 평가\n",
    "# 훈련 및 검증 데이터에 대한 손실 및 정확도 그래프\n",
    "train_loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "train_accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_accuracy, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracy, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# 예측 및 성능 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(Y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. STFT + LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "# LSTM Autoencoder 모델 정의\n",
    "def create_lstm_autoencoder(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # Encoder\n",
    "    encoded = LSTM(64, return_sequences=True)(inputs)\n",
    "    encoded = LSTM(32, return_sequences=False)(encoded)\n",
    "    # Repeat Vector\n",
    "    repeated = RepeatVector(input_shape[0])(encoded)\n",
    "    # Decoder\n",
    "    decoded = LSTM(32, return_sequences=True)(repeated)\n",
    "    decoded = LSTM(64, return_sequences=True)(decoded)\n",
    "    outputs = TimeDistributed(Dense(input_shape[1]))(decoded)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder에 인코딩된 특징을 활용하여 분류 모델 생성\n",
    "def create_classifier(input_shape, num_classes):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(64, input_shape=input_shape))\n",
    "    classifier.add(LeakyReLU(alpha=0.01))  # Leaky ReLU activation function\n",
    "    classifier.add(Dropout(0.5))\n",
    "    classifier.add(Dense(32))\n",
    "    classifier.add(LeakyReLU(alpha=0.01))  # Leaky ReLU activation function\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    classifier.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder 모델 생성\n",
    "model = create_lstm_autoencoder(input_shape)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_val, X_val),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 검증 데이터에 대한 손실 그래프\n",
    "train_loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Autoencoder에서 인코딩된 특징 추출\n",
    "encoder = Model(inputs=model.input, outputs=model.layers[2].output)\n",
    "X_train_encoded = encoder.predict(X_train)\n",
    "X_val_encoded = encoder.predict(X_val)\n",
    "X_test_encoded = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 클래스 분류 모델 생성\n",
    "classifier = create_classifier((X_train_encoded.shape[1],), 5)\n",
    "classifier.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 클래스 분류 모델 훈련\n",
    "history = classifier.fit(\n",
    "    X_train_encoded,\n",
    "    Y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val_encoded, Y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 검증 데이터에 대한 손실 및 정확도 그래프\n",
    "train_loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "train_accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_accuracy, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracy, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = classifier.evaluate(X_test_encoded, Y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# 예측 및 성능 평가\n",
    "y_pred = classifier.predict(X_test_encoded)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(Y_test, axis=1)\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. STFT + Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer 모델 생성\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "def create_transformer_model(input_shape, num_heads=4, ff_dim=32):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=input_shape[1])(\n",
    "        inputs, inputs\n",
    "    )\n",
    "    attn_output = Dropout(0.1)(attn_output)\n",
    "    attn_output = LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
    "\n",
    "    ff_output = Dense(ff_dim, activation=\"relu\")(attn_output)\n",
    "    ff_output = Dense(input_shape[1])(ff_output)\n",
    "    ff_output = Dropout(0.1)(ff_output)\n",
    "    ff_output = LayerNormalization(epsilon=1e-6)(ff_output + attn_output)\n",
    "\n",
    "    outputs = GlobalAveragePooling1D()(ff_output)\n",
    "    outputs = Dense(5, activation=\"softmax\")(outputs)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer 모델 생성\n",
    "model = create_transformer_model(input_shape)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 검증 데이터에 대한 손실 및 정확도 그래프\n",
    "train_loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "train_accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_accuracy, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracy, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    " \n",
    "# 예측 및 성능 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(Y_test, axis=1)\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. STFT + LSTM AutoEncoder + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "# LSTM Autoencoder 모델 정의 (Attention 추가)\n",
    "def create_lstm_ae_with_attention(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    encoded = LSTM(64, return_sequences=True)(inputs)\n",
    "    encoded = LSTM(32, return_sequences=True)(encoded)\n",
    "    attention = Attention()(encoded)\n",
    "    repeated = RepeatVector(input_shape[0])(attention)\n",
    "    decoded = LSTM(32, return_sequences=True)(repeated)\n",
    "    decoded = LSTM(64, return_sequences=True)(decoded)\n",
    "    outputs = TimeDistributed(Dense(input_shape[1]))(decoded)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder 모델 생성\n",
    "model = create_lstm_ae_with_attention(input_shape)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_val, X_val),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 검증 데이터에 대한 손실 그래프\n",
    "train_loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Autoencoder에서 인코딩된 특징 추출\n",
    "encoder = Model(inputs=model.input, outputs=model.layers[3].output)\n",
    "X_train_encoded = encoder.predict(X_train)\n",
    "X_val_encoded = encoder.predict(X_val)\n",
    "X_test_encoded = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 클래스 분류 모델 생성\n",
    "classifier = create_classifier((X_train_encoded.shape[1],), 5)\n",
    "classifier.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 클래스 분류 모델 훈련\n",
    "history = classifier.fit(\n",
    "    X_train_encoded,\n",
    "    Y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val_encoded, Y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 검증 데이터에 대한 손실 및 정확도 그래프\n",
    "train_loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "train_accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "plt.plot(train_accuracy, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracy, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = classifier.evaluate(X_test_encoded, Y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# 예측 및 성능 평가\n",
    "y_pred = classifier.predict(X_test_encoded)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(Y_test, axis=1)\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  STFT + Conv LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvLSTM + Attention 모델 생성\n",
    "def create_convlstm(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv_lstm = ConvLSTM2D(\n",
    "        filters=64, kernel_size=(3, 1), padding=\"same\", return_sequences=True\n",
    "    )(inputs)\n",
    "    conv_lstm = BatchNormalization()(conv_lstm)\n",
    "    conv_lstm = ConvLSTM2D(\n",
    "        filters=32, kernel_size=(3, 1), padding=\"same\", return_sequences=True\n",
    "    )(conv_lstm)\n",
    "    conv_lstm = BatchNormalization()(conv_lstm)\n",
    "\n",
    "    conv_lstm_decoded = ConvLSTM2D(\n",
    "        filters=32, kernel_size=(3, 1), padding=\"same\", return_sequences=True\n",
    "    )(conv_lstm)\n",
    "    conv_lstm_decoded = BatchNormalization()(conv_lstm_decoded)\n",
    "    conv_lstm_decoded = ConvLSTM2D(\n",
    "        filters=64, kernel_size=(3, 1), padding=\"same\", return_sequences=True\n",
    "    )(conv_lstm_decoded)\n",
    "    conv_lstm_decoded = BatchNormalization()(conv_lstm_decoded)\n",
    "    outputs = Flatten()(conv_lstm_decoded)\n",
    "    outputs = Dense(5, activation=\"softmax\")(outputs)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변환\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2], 1, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1], X_val.shape[2], 1, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 형태 확인\n",
    "print(\"Train data shape:\", X_train.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(\"Train label shape:\", Y_train.shape)\n",
    "print(\"Validation label shape:\", Y_val.shape)\n",
    "print(\"Test label shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 형태 정의\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3], X_train.shape[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvLSTM 모델 생성\n",
    "model = create_convlstm(input_shape)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 검증 데이터에 대한 손실 및 정확도 그래프\n",
    "train_loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "train_accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_accuracy, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracy, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# 예측 및 성능 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(Y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-job",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

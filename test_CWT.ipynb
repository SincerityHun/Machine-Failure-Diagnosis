{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: seaborn in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from seaborn) (3.8.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from seaborn) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.49.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: fsspec in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (3.8.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scipy in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from scipy) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pyWavelets in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3,>=1.22.4 in /home/seonghun/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages (from pyWavelets) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install torch\n",
    "!pip install matplotlib\n",
    "!pip install scipy\n",
    "!pip install scikit-learn\n",
    "!pip install pyWavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.fft import fft, ifft\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU is available and set as the current device.\n",
      "Current GPU Device: index[0]\n",
      "Device name: NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # 사용 가능한 GPU의 개수\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "    # Device 세팅\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and set as the current device.\")\n",
    "\n",
    "    # 현재 device로 설정된 GPU 확인\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(f\"Current GPU Device: index[{current_device}]\")\n",
    "    \n",
    "    # 현재 device로 설정된 GPU의 이름 출력\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(current_device)}\")\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"GPU is not available, using CPU instead.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor1 = pd.read_csv(\"raw_data/g1_sensor1.csv\",names=[\"time\",\"normal\",\"type1\",\"type2\",\"type3\"])\n",
    "sensor2 = pd.read_csv(\"raw_data/g1_sensor2.csv\",names=[\"time\",\"normal\",\"type1\",\"type2\",\"type3\"])\n",
    "sensor3 = pd.read_csv(\"raw_data/g1_sensor3.csv\",names=[\"time\",\"normal\",\"type1\",\"type2\",\"type3\"])\n",
    "sensor4 = pd.read_csv(\"raw_data/g1_sensor4.csv\",names=[\"time\",\"normal\",\"type1\",\"type2\",\"type3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor 1의 데이터 크기 (190218, 5)\n",
      "sensor 1의 데이터 크기 (184211, 5)\n",
      "sensor 1의 데이터 크기 (196079, 5)\n",
      "sensor 1의 데이터 크기 (183969, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"sensor 1의 데이터 크기\",sensor1.shape) # 190218개의 행, 5의 열\n",
    "print(\"sensor 1의 데이터 크기\",sensor2.shape)\n",
    "print(\"sensor 1의 데이터 크기\",sensor3.shape)\n",
    "print(\"sensor 1의 데이터 크기\",sensor4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "x_new = np.arange(0,140,0.001) # 0,0.001,0.002,,,,,,139.999\n",
    "y_new1 = []\n",
    "y_new2 = []\n",
    "y_new3 = []\n",
    "y_new4 = []\n",
    "\n",
    "# 모든 센서의 각 타입 데이터 별로 선형 보간을 수행한 결과를 추출\n",
    "for item in [\"normal\",\"type1\",\"type2\",\"type3\"]:\n",
    "    f_linear1 = interpolate.interp1d(sensor1[\"time\"],sensor1[item],kind=\"linear\") \n",
    "    y_new1.append(f_linear1(x_new)) \n",
    "\n",
    "    f_linear2 = interpolate.interp1d(sensor2[\"time\"],sensor2[item],kind=\"linear\")\n",
    "    y_new2.append(f_linear2(x_new))\n",
    "    f_linear3 = interpolate.interp1d(sensor3[\"time\"],sensor3[item],kind=\"linear\")\n",
    "    y_new3.append(f_linear3(x_new))\n",
    "    f_linear4 = interpolate.interp1d(sensor4[\"time\"],sensor4[item],kind=\"linear\")\n",
    "    y_new4.append(f_linear4(x_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>normal</th>\n",
       "      <th>type1</th>\n",
       "      <th>type2</th>\n",
       "      <th>type3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.853307</td>\n",
       "      <td>-3.464579</td>\n",
       "      <td>0.555219</td>\n",
       "      <td>3.919664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000736</td>\n",
       "      <td>-0.740463</td>\n",
       "      <td>-2.448986</td>\n",
       "      <td>-0.234687</td>\n",
       "      <td>4.145351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001472</td>\n",
       "      <td>-0.138630</td>\n",
       "      <td>-1.922383</td>\n",
       "      <td>-0.009000</td>\n",
       "      <td>2.941685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.049443</td>\n",
       "      <td>-0.906790</td>\n",
       "      <td>-0.272301</td>\n",
       "      <td>2.603155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002944</td>\n",
       "      <td>-0.289088</td>\n",
       "      <td>-0.568259</td>\n",
       "      <td>-0.986978</td>\n",
       "      <td>1.361874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190213</th>\n",
       "      <td>139.996768</td>\n",
       "      <td>-1.156354</td>\n",
       "      <td>-2.696750</td>\n",
       "      <td>0.844491</td>\n",
       "      <td>-2.109427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190214</th>\n",
       "      <td>139.997504</td>\n",
       "      <td>-0.930666</td>\n",
       "      <td>-1.380241</td>\n",
       "      <td>0.919720</td>\n",
       "      <td>-2.222270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190215</th>\n",
       "      <td>139.998240</td>\n",
       "      <td>-0.554521</td>\n",
       "      <td>-2.132532</td>\n",
       "      <td>0.731647</td>\n",
       "      <td>-2.109427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190216</th>\n",
       "      <td>139.998976</td>\n",
       "      <td>-1.419655</td>\n",
       "      <td>-2.433448</td>\n",
       "      <td>1.183022</td>\n",
       "      <td>-3.087405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190217</th>\n",
       "      <td>139.999712</td>\n",
       "      <td>-0.441677</td>\n",
       "      <td>-2.245376</td>\n",
       "      <td>1.333480</td>\n",
       "      <td>-2.184656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time    normal     type1     type2     type3\n",
       "0         0.000000 -0.853307 -3.464579  0.555219  3.919664\n",
       "1         0.000736 -0.740463 -2.448986 -0.234687  4.145351\n",
       "2         0.001472 -0.138630 -1.922383 -0.009000  2.941685\n",
       "3         0.002208  0.049443 -0.906790 -0.272301  2.603155\n",
       "4         0.002944 -0.289088 -0.568259 -0.986978  1.361874\n",
       "...            ...       ...       ...       ...       ...\n",
       "190213  139.996768 -1.156354 -2.696750  0.844491 -2.109427\n",
       "190214  139.997504 -0.930666 -1.380241  0.919720 -2.222270\n",
       "190215  139.998240 -0.554521 -2.132532  0.731647 -2.109427\n",
       "190216  139.998976 -1.419655 -2.433448  1.183022 -3.087405\n",
       "190217  139.999712 -0.441677 -2.245376  1.333480 -2.184656\n",
       "\n",
       "[190218 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간축을 기준으로, 모든 센서에서 추출된 데이터를 이어붙인다.\n",
    "normal_ = pd.concat([sensor1[\"normal\"],sensor2[\"normal\"],sensor3[\"normal\"],sensor4[\"normal\"]],axis=1) # 각 센서에서 추출된 normal 데이터 \n",
    "type1_ = pd.concat([sensor1[\"type1\"],sensor2[\"type1\"],sensor3[\"type1\"],sensor4[\"type1\"]],axis=1) # Type 1 이상치 데이터\n",
    "type2_ = pd.concat([sensor1[\"type2\"],sensor2[\"type2\"],sensor3[\"type2\"],sensor4[\"type2\"]],axis=1) # Type 2 이상치 데이터\n",
    "type3_ = pd.concat([sensor1[\"type3\"],sensor2[\"type3\"],sensor3[\"type3\"],sensor4[\"type3\"]],axis=1) # Type 3 이상치 데이터\n",
    "\n",
    "# 어디 센서에서 나온 결과인지, 열의 이름 달기\n",
    "normal_.columns = [\"s1\",\"s2\",\"s3\",\"s4\"]\n",
    "type1_.columns = [\"s1\",\"s2\",\"s3\",\"s4\"]\n",
    "type2_.columns = [\"s1\",\"s2\",\"s3\",\"s4\"]\n",
    "type3_.columns = [\"s1\",\"s2\",\"s3\",\"s4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본적인 분포\n",
    "    * 주파수가 현재 normal, type1, type2, type3가 달라서, 정규 분포가 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.scatter(range(0,300),normal_[\"s1\"][:300],label=\"class=\"+str(1),marker='o',s =5) # x축: (0,300), y축: normal_[\"s1\"][:300]\n",
    "# plt.scatter(range(0,300),type1_[\"s1\"][:300],label=\"class=\"+str(2),marker='o',s =5)\n",
    "# plt.scatter(range(0,300),type2_[\"s1\"][:300],label=\"class=\"+str(3),marker='o',s =5)\n",
    "# plt.scatter(range(0,300),type3_[\"s1\"][:300],label=\"class=\"+str(4),marker='o',s =5)\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"Sensor\",fontsize=15)\n",
    "plt.ylabel(\"Sensor Value\",fontsize=15)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주어진 주파수를 Morlet 웨이블릿을 활용해 CWT변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웨이블릿 생성 코드\n",
    "def psi(T, f0=6):\n",
    "    '''\n",
    "\t  T : parameter for adjusting length of wavelet\n",
    "\t  f0 : parameter for time-frequenct resolution trade off \n",
    "    '''\n",
    "    x = np.linspace(-2 * np.pi, 2 * np.pi, T)\n",
    "    return (np.pi ** -0.25) * np.exp(1j * f0 * x - x ** 2 / 2)\n",
    "\n",
    "# 특정 웨이블릿과 주어진 신호 사이의 상관계수 Convolution 연산 코드\n",
    "def wavelet_convolution(tup):\n",
    "    f = tup[0]\n",
    "    T = tup[1]\n",
    "    f_len = np.shape(f)[0]\n",
    "    f_hat = np.append(f, np.zeros(T))\n",
    "    h = psi(T)\n",
    "    h_hat = np.append(h, np.zeros(f_len))\n",
    "    return ifft(fft(f_hat)*fft(h_hat))[round(T/2) : round(T/2) + f_len]\n",
    "\n",
    "# 전체 시간의 CWT 출력\n",
    "def cwt(f, t0 = 20):\n",
    "    '''\n",
    "    f : input signal\n",
    "    t0 : minimum length of wavelet\n",
    "    '''\n",
    "    f_len = np.shape(f)[0]\n",
    "    result = np.array(list(map(wavelet_convolution, [(f, x) for x in range(t0, f_len, 10)])))\n",
    "    return result\n",
    "\n",
    "# 기본 Input 시그널 확인\n",
    "input_signal = normal_[\"s1\"]\n",
    "print(np.shape(input_signal))\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(range(0, 300), input_signal[:300], label=\"class=\" + str(1))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 활용한 CWT 변환\n",
    "wavelet = 'cmor'\n",
    "scales = np.arange(1,64) # 스케일이 커질 수록, 낮은 주파수 성분을 잡아낼 수 있음\n",
    "coefficients, frequencies = pywt.cwt(input_signal, scales, wavelet)\n",
    "# CWT 결과를 시각화합니다.\n",
    "print(np.abs(coefficients))\n",
    "plt.imshow(np.abs(coefficients), extent=[0, len(input_signal), frequencies[-1], frequencies[0]], aspect='auto')\n",
    "plt.yscale('log')\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.title('Continuous Wavelet Transform (CWT)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CWT 변환 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply_cwt 함수 정의: 각 센서 데이터에 대해 CWT를 적용합니다.\n",
    "def apply_cwt(data, scales, wavelet='cmor'):\n",
    "    cwt_coeffs = []\n",
    "    for column in data:\n",
    "        sensor_data = data[column].values  # Pandas Series를 numpy 배열로 변환\n",
    "        if sensor_data.ndim != 1:\n",
    "            raise ValueError(f\"Data for sensor {column} is not 1-dimensional.\")\n",
    "        # 연속 웨이블릿 변환 적용\n",
    "        cwt_matrix, frequencies = pywt.cwt(sensor_data, scales, wavelet)\n",
    "        # 해당 시계열의 cwt_matrix의 절댓값이 가장 큰 값의 frequencies을 넣어준다.\n",
    "        # Find the index of the max coefficient at each time point across all scales\n",
    "        cwt_coeffs.append(np.mean(np.abs(cwt_matrix),axis=0))  # 결과를 1차원으로 평탄\n",
    "        # cwt_coeffs.append(np.abs(cwt_matrix))  # 결과를 1차원으로 평탄\n",
    "    # numpy 배열로 변환\n",
    "    return np.column_stack(cwt_coeffs)\n",
    "\n",
    "wavelet = 'morl'\n",
    "scales = np.arange(1,128) # 스케일이 커질 수록, 낮은 주파수 성분을 잡아낼 수 있음-> 이거 그냥 128이 제일 잘 나와서 이걸로 함\n",
    "\n",
    "# 각 데이터셋에 대해 CWT 변환 적용\n",
    "normal_cwt = apply_cwt(normal_, scales,wavelet)\n",
    "type1_cwt = apply_cwt(type1_, scales,wavelet)\n",
    "type2_cwt = apply_cwt(type2_, scales,wavelet)\n",
    "type3_cwt = apply_cwt(type3_, scales,wavelet)\n",
    "\n",
    "# CWT 결과를 시각화하는 함수 정의\n",
    "def visualize_cwt(coefficients, sensor_index, scales):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(np.abs(coefficients[sensor_index]), extent=[0, len(coefficients[sensor_index][0]), scales[-1], scales[0]], aspect='auto', cmap='viridis')\n",
    "    plt.yscale('log')\n",
    "    plt.colorbar(label='Magnitude')\n",
    "    plt.title(f'Continuous Wavelet Transform (CWT) - Sensor {sensor_index + 1}')\n",
    "    plt.ylabel('Scale')\n",
    "    plt.xlabel('Time')\n",
    "    plt.show()\n",
    "\n",
    "# # 각 센서에 대한 CWT 결과를 시각화\n",
    "# for i in range(normal_cwt.shape[0]):  # normal_cwt의 첫 번째 차원은 센서의 개수를 나타냄\n",
    "#     visualize_cwt(normal_cwt, i, scales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8227721  0.02232312 0.18723753 0.64755034]\n",
      " [0.86026309 0.02274812 0.21643891 0.65671693]\n",
      " [0.88677547 0.02097016 0.18492444 0.68254407]\n",
      " ...\n",
      " [       nan        nan 0.15908884        nan]\n",
      " [       nan        nan 0.1855482         nan]\n",
      " [       nan        nan 0.14541616        nan]]\n"
     ]
    }
   ],
   "source": [
    "print(normal_cwt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196065, 4) (196079, 4)\n",
      "(196065, 8)\n"
     ]
    }
   ],
   "source": [
    "M =15 # 이동평균 필터 사이즈\n",
    "def apply_moving_average(data):\n",
    "    # 이동 평균 적용 및 데이터 재구성\n",
    "    temp = [np.convolve(data[col], np.ones(M), 'valid') / M for col in data.columns]\n",
    "    return np.column_stack(temp)\n",
    "\n",
    "# 이동 평균 필터 적용 -> 노이즈 제거용\n",
    "normal_ma = apply_moving_average(normal_)\n",
    "type1_ma = apply_moving_average(type1_)\n",
    "type2_ma = apply_moving_average(type2_)\n",
    "type3_ma = apply_moving_average(type3_)\n",
    "# CWT 결과와 이동평균 결과 결합\n",
    "print(np.shape(normal_ma),np.shape(normal_cwt))\n",
    "# CWT 결과 중 필요한 부분만 슬라이싱하여 이동 평균 결과와 결합\n",
    "start_index = 14  # 이동 평균을 적용했을 때 데이터가 얼마나 줄어드는지에 따라 조정\n",
    "normal_features = np.concatenate((normal_ma, normal_cwt[start_index:, :]), axis=1)\n",
    "type1_features = np.concatenate((type1_ma, type1_cwt[start_index:, :]), axis=1)\n",
    "type2_features = np.concatenate((type2_ma, type2_cwt[start_index:, :]), axis=1)\n",
    "type3_features = np.concatenate((type3_ma, type3_cwt[start_index:, :]), axis=1)\n",
    "print(np.shape(normal_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(normal_features) # normal_데이터셋의 데이터 분포가 어떻게 정규화되어 있는지 학습\n",
    "\n",
    "# normal_ 데이터셋 분포에 맞게 다른 모든 데이터 셋의 분포를 전환\n",
    "normal= scaler.fit_transform(normal_features)\n",
    "type1 = scaler.transform(type1_features)\n",
    "type2= scaler.transform(type2_features)\n",
    "type3= scaler.transform(type3_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA SPLIT ->(Train, Valid, Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normal)\n",
    "print('------------------------------------------------')\n",
    "print('normal data size = ', normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16608663 0.24142403 0.65540271 ... 0.39556499 0.39773571 0.5137881 ]\n",
      " [0.20355286 0.30149987 0.74105389 ... 0.37513478 0.43376648 0.49938631]\n",
      " [0.25150963 0.34808931 0.70578576 ... 0.36992695 0.52539575 0.45351994]\n",
      " ...\n",
      " [0.89069226 0.67760602 0.64719082 ... 0.30389267 0.41278895 0.33555213]\n",
      " [0.9101747  0.66902375 0.67238234 ... 0.36512475 0.33483116 0.27817251]\n",
      " [0.91467065 0.68496224 0.70261216 ... 0.41406542 0.4410758  0.22361346]]\n",
      "------------------------------------------------\n",
      "normal data size =  (100000, 8)\n"
     ]
    }
   ],
   "source": [
    "# 끝에 NAN 쓰레기값, 초반에 불안정함때문에 중간 100,000개만 데이터로 사용\n",
    "normal = normal[30000:130000][:]\n",
    "type1 = type1[30000:130000][:]\n",
    "type2 = type2[30000:130000][:]\n",
    "type3 = type3[30000:130000][:]\n",
    "print(normal)\n",
    "print('------------------------------------------------')\n",
    "print('normal data size = ', normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data의 형태: (240000, 8)\n",
      "valid data의 형태: (80000, 8)\n",
      " test data의 형태: (80000, 8)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분배, train = 60,000개, valid = 20,000개, test = 20,000개 \n",
    "normal_train = normal[:][:60000]; normal_valid = normal[:][60000:80000]; normal_test =normal[:][80000:]\n",
    "type1_train = type1[:][:60000]; type1_valid = type1[:][60000:80000]; type1_test =type1[:][80000:]\n",
    "type2_train = type2[:][:60000]; type2_valid = type2[:][60000:80000]; type2_test =type2[:][80000:]\n",
    "type3_train = type3[:][:60000]; type3_valid = type3[:][60000:80000]; type3_test =type3[:][80000:]\n",
    "\n",
    "# 데이터 합치기\n",
    "train = np.concatenate((normal_train,type1_train,type2_train,type3_train))\n",
    "valid = np.concatenate((normal_valid,type1_valid,type2_valid,type3_valid))\n",
    "test = np.concatenate((normal_test,type1_test,type2_test,type3_test))\n",
    "print(\"train data의 형태:\", train.shape) # normal_train -> type1_train -> type2_train -> type3_train: 같은 분포\n",
    "print(\"valid data의 형태:\", valid.shape)\n",
    "print(\" test data의 형태:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 예측한 결과값을 담을 데이터 구조 생성\n",
    "train_label = np.concatenate((np.full((60000,1),0), np.full((60000,1),1),\n",
    "np.full((60000,1),2), np.full((60000,1),3)))\n",
    "valid_label = np.concatenate((np.full((20000,1),0), np.full((20000,1),1),\n",
    "np.full((20000,1),2), np.full((20000,1),3)))\n",
    "test_label = np.concatenate((np.full((20000,1),0), np.full((20000,1),1),\n",
    "np.full((20000,1),2), np.full((20000,1),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data, valid data, test data 전부 index 셔플\n",
    "idx = np.arange(train.shape[0]); np.random.shuffle(idx)\n",
    "train = train[:][idx]; train_label = train_label[:][idx]\n",
    "\n",
    "idx_v = np.arange(valid.shape[0]); np.random.shuffle(idx_v)\n",
    "valid = valid[:][idx_v]; valid_label = valid_label[:][idx_v]\n",
    "\n",
    "idx_t = np.arange(test.shape[0]); np.random.shuffle(idx_t)\n",
    "test = test[:][idx_t]; test_label = test_label[:][idx_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변경 전\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.10454838,  0.78863303,  0.3651196 , ...,  0.37666972,\n",
       "         0.20405988,  0.12589455],\n",
       "       [ 0.3933325 ,  0.56152873,  0.70942175, ...,  0.48716256,\n",
       "         0.46488267,  0.46415813],\n",
       "       [ 0.62678659,  0.7028152 ,  0.41697871, ...,  0.45803473,\n",
       "         0.22451981,  0.50684092],\n",
       "       ...,\n",
       "       [ 0.31013402,  0.67497433,  0.59641909, ...,  0.41996194,\n",
       "         0.44791387,  0.39846077],\n",
       "       [ 1.10418833, -0.12154171,  0.32748978, ...,  1.1171094 ,\n",
       "         0.40330703,  0.37342298],\n",
       "       [ 1.22612621,  0.52486016,  0.41267845, ...,  0.94664145,\n",
       "         0.15608568,  0.35559713]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토치 텐서로 변환, 그냥 좀 절삭\n",
    "x_train = torch.from_numpy(train).float()\n",
    "y_train = torch.from_numpy(train_label).float().T[0]\n",
    "x_valid = torch.from_numpy(valid).float()\n",
    "y_valid = torch.from_numpy(valid_label).float().T[0]\n",
    "x_test = torch.from_numpy(test).float()\n",
    "y_test = torch.from_numpy(test_label).float().T[0]\n",
    "print(\"변경 전\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"변경 후\")\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "# 데이터셋 생성 및 배치사이즈로 미리 나누며 iterator 생성\n",
    "BATCH_SIZE = 4096\n",
    "train = TensorDataset(x_train, y_train)\n",
    "train_dataloader = DataLoader(train, batch_size =BATCH_SIZE, shuffle=True)\n",
    "valid = TensorDataset(x_valid, y_valid)\n",
    "valid_dataloader = DataLoader(valid, batch_size =len(x_valid), shuffle=False)\n",
    "test = TensorDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test, batch_size =len(x_valid), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET AI MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KAMP_DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KAMP_DNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_features =4, out_features =100)\n",
    "        self.layer2 = nn.Linear(in_features =100, out_features =100)\n",
    "        self.layer3 = nn.Linear(in_features =100, out_features =100)\n",
    "        self.layer4 = nn.Linear(in_features =100, out_features =4)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, input):\n",
    "        out =self.layer1(input)\n",
    "        out =self.relu(out)\n",
    "        out =self.dropout(out)\n",
    "\n",
    "        out =self.layer2(out)\n",
    "        out =self.relu(out)\n",
    "        out =self.dropout(out)\n",
    "\n",
    "        out =self.layer3(out)\n",
    "        out =self.relu(out)\n",
    "        out =self.dropout(out)\n",
    "\n",
    "        out =self.layer4(out)\n",
    "        return out\n",
    "\n",
    "model_check = KAMP_DNN()\n",
    "print(model_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAMP_CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(1, 100, kernel_size=(2,), stride=(1,), padding=same)\n",
      "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(100, 100, kernel_size=(2,), stride=(1,), padding=same)\n",
      "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(100, 100, kernel_size=(2,), stride=(1,), padding=same)\n",
      "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv1d(100, 4, kernel_size=(2,), stride=(1,), padding=same)\n",
      "    (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (final_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class KAMP_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KAMP_CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "        nn.Conv1d(in_channels=1, out_channels=100, kernel_size=2, stride=1, padding='same'),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=1, stride=1),\n",
    "        nn.Dropout(p=0.2))\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "        nn.Conv1d(in_channels=100, out_channels=100, kernel_size=2, stride=1, padding='same'),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=1, stride=1),\n",
    "        nn.Dropout(p=0.2))\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "        nn.Conv1d(in_channels=100, out_channels=100, kernel_size=2, stride=1, padding='same'),\n",
    "        nn.BatchNorm1d(100),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=1, stride=1),\n",
    "        nn.Dropout(p=0.2))\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "        nn.Conv1d(in_channels=100, out_channels=4, kernel_size=2, stride=1, padding='same'),\n",
    "        nn.BatchNorm1d(4),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool1d(kernel_size=1, stride=1))\n",
    "\n",
    "        self.final_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.linear = nn.Linear(4, 4)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = input.unsqueeze(1)\n",
    "        out =self.conv1(input)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out =self.conv4(out)\n",
    "        out =self.final_pool(out)\n",
    "        out =self.linear(out.squeeze(-1))\n",
    "        return out\n",
    "model_check = KAMP_CNN()\n",
    "print(model_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------------------------------------------------------------------')\n",
    "input = torch.tensor([[[0.0, 6.0, 9.0, 1.0]]])\n",
    "print('\"input is same below.\"')\n",
    "print(input)\n",
    "print('--------------------------------------------------------------------')\n",
    "model = nn.Conv1d(1, 4, 2, bias =False)\n",
    "model.weight.data = torch.zeros(model.weight.data.size())\n",
    "model.weight.data[:, :, :2] =1\n",
    "print('\"kernal is same below.\"')\n",
    "print(model.weight.data)\n",
    "print('--------------------------------------------------------------------')\n",
    "output = model(input)\n",
    "print('\"output is same below (without bias).\"')\n",
    "print(output)\n",
    "print('--------------------------------------------------------------------')\n",
    "model1 = nn.Conv1d(1, 4, 2)\n",
    "model1.weight.data = torch.zeros(model1.weight.data.size())\n",
    "model1.weight.data[:, :, :2] =1\n",
    "output = model1(input)\n",
    "print('\"output is same below (with bias).\"')\n",
    "print(output)\n",
    "print('--------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class KAMP_RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KAMP_RNN, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size =4, hidden_size =100, num_layers =2,\n",
    "        batch_first=True, dropout =0.2)\n",
    "        self.fc = nn.Linear(in_features =100, out_features =4)\n",
    "    def forward(self, input):\n",
    "        input = input.unsqueeze(1)\n",
    "        out, _ =self.lstm(input)\n",
    "        out = out.view(-1,100)\n",
    "        output =self.fc(out)\n",
    "        return output\n",
    "\n",
    "model_check = KAMP_RNN()\n",
    "print(model_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU: device\n",
    "def train_model(model, criterion, optimizer, num_epoch, train_dataloader, PATH):\n",
    " # Model을 GPU로 이동\n",
    " model.to(device)\n",
    "\n",
    " \n",
    " loss_values = []\n",
    " loss_values_v = [] \n",
    " accuracy_past =0\n",
    " for epoch in range(1, num_epoch +1):\n",
    "    #---------------------- 모델 학습 ---------------------#\n",
    "    model.train()\n",
    "    batch_number =0\n",
    "    running_loss =0.0\n",
    "    for batch_idx, samples in enumerate(train_dataloader):\n",
    "        # 데이터 GPU로 옮기기\n",
    "        x_train, y_train = samples[0].to(device), samples[1].to(device) \n",
    "\n",
    "        # 변수 초기화\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model.forward(x_train)\n",
    "        loss = criterion(y_hat,y_train.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        batch_number +=1\n",
    "\n",
    "    loss_values.append(running_loss / batch_number)\n",
    " #---------------------- 모델 검증 ---------------------#\n",
    "    model.eval()\n",
    "    accuracy =0.0\n",
    "    total =0.0\n",
    "    for batch_idx, data in enumerate(valid_dataloader):\n",
    "        x_valid, y_valid = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        v_hat = model.forward(x_valid)\n",
    "        v_loss = criterion(v_hat,y_valid.long())\n",
    "        _, predicted = torch.max(v_hat.data, 1)\n",
    "        total += y_valid.size(0)\n",
    "        accuracy += (predicted == y_valid).sum().item()\n",
    "    loss_values_v.append(loss.item())\n",
    "    accuracy = (accuracy / total)\n",
    " #----------------Check for early stopping---------------#\n",
    "    if epoch % 1 ==0:\n",
    "        print('[Epoch {}/{}] [Train_Loss: {:.6f} /Valid_Loss: {:.6f}]'.format(epoch, num_epochs, loss.item(),v_loss.item()))\n",
    "        print('[Epoch {}/{}] [Accuracy : {:.6f}]'.format(epoch, num_epochs, accuracy))\n",
    "    \n",
    "    # checkpoint + early stopping\n",
    "    if accuracy_past < accuracy:\n",
    "        accuracy_past = accuracy\n",
    "        torch.save(model.state_dict(), PATH + f'model_epoch_{epoch}_acc_{accuracy:.4f}.pt')\n",
    "        print(f\"Checkpoint saved at epoch {epoch} with validation accuracy {accuracy:.4f}.\")\n",
    "\n",
    "# return loss..\n",
    " return loss_values, loss_values_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 3.94 GiB of which 87.12 MiB is free. Including non-PyTorch memory, this process has 3.79 GiB memory in use. Of the allocated memory 3.66 GiB is allocated by PyTorch, and 37.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(CNN_model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m      5\u001b[0m PATH \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave/CNN/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m CNN_loss_values, CNN_loss_values_v \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCNN_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 36\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epoch, train_dataloader, PATH)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(valid_dataloader):\n\u001b[1;32m     34\u001b[0m     x_valid, y_valid \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 36\u001b[0m     v_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     v_loss \u001b[38;5;241m=\u001b[39m criterion(v_hat,y_valid\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m     38\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(v_hat\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 36\u001b[0m, in \u001b[0;36mKAMP_CNN.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     out \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[1;32m     38\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(out)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/torch/nn/modules/activation.py:101\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ml-job/lib/python3.10/site-packages/torch/nn/functional.py:1473\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 3.94 GiB of which 87.12 MiB is free. Including non-PyTorch memory, this process has 3.79 GiB memory in use. Of the allocated memory 3.66 GiB is allocated by PyTorch, and 37.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "CNN_model = KAMP_CNN()\n",
    "num_epochs =1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(CNN_model.parameters())\n",
    "PATH ='save/CNN/'\n",
    "CNN_loss_values, CNN_loss_values_v = train_model(CNN_model, criterion, optimizer,\n",
    "num_epochs, train_dataloader, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model = KAMP_RNN()\n",
    "num_epochs =1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(RNN_model.parameters())\n",
    "PATH ='save/RNN/'\n",
    "RNN_loss_values, RNN_loss_values_v = train_model(RNN_model, criterion, optimizer,\n",
    "num_epochs, train_dataloader, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, PATH):\n",
    "    model = torch.load(PATH +'model.pt')\n",
    "    #---------------------- 모델 시험 ---------------------#\n",
    "    model.eval()\n",
    "    total =0.0\n",
    "    accuracy =0.0\n",
    "    for batch_idx, data in enumerate(test_dataloader):\n",
    "        x_test, y_test = data[0].to(device),data[1].to(device)\n",
    "\n",
    "        t_hat = model(x_test)\n",
    "        _, predicted = torch.max(t_hat.data, 1)\n",
    "        total += y_test.size(0)\n",
    "        accuracy += (predicted == y_test).sum().item()\n",
    "    accuracy = (accuracy / total)\n",
    "    #------------------------------------------------------#\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def draw_confusion_matrix(model, xt, yt, PATH):\n",
    "    y_pred = []; y_true = []\n",
    "    # 1. 모델 예측 결과 뽑기\n",
    "    model.eval()\n",
    "    y_hat = model(xt) # y_hat은 모델로 예측한 결과\n",
    "    output = (torch.max(torch.exp(y_hat), 1)[1]).data.cpu().numpy() # 결과값만 추출 \n",
    "    y_pred.extend(output)\n",
    "\n",
    "    # 2. 실제 정답값 뽑기\n",
    "    labels = y_test.data.cpu().numpy()\n",
    "    y_true.extend(labels)\n",
    "    # 분류 항목\n",
    "    classes = ('Normal', 'Type1', 'Type2', 'Type3')\n",
    "\n",
    "    # Confussion Matrix 생성\n",
    "    plt.figure(figsize = (7,5))\n",
    "    dlen = float(len(x_test)) # test data 크기 : 여기서는 80000\n",
    "    cm = confusion_matrix(y_true, y_pred) \n",
    "\n",
    "    df_cm = pd.DataFrame(cm/dlen, index = [i for i in classes],columns = [i for i in classes])\n",
    "    sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\", size=24, fontweight='bold')\n",
    "    plt.xlabel(\"Predicted Label\", size=16); plt.ylabel(\"Actual Label\", size=16)\n",
    "    plt.rc('xtick', labelsize=12); plt.rc('ytick', labelsize=12); plt.yticks(rotation=0)\n",
    "    plt.savefig(PATH +'cm_output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_graph(loss_values, loss_values_v):\n",
    "    plt.figure()\n",
    "    plt.plot(loss_values)\n",
    "    plt.plot(loss_values_v)\n",
    "    plt.title(\"Training & Validation Loss\")\n",
    "    plt.ylabel(\"loss\", fontsize=\"large\")\n",
    "    plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "    plt.legend([\"train\", \"validation\"])\n",
    "    plt.tight_layout()\n",
    "    # 결과 저장\n",
    "    plt.savefig(PATH +'lossplot_output.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(CNN_model,'save/CNN/')\n",
    "# test_model(RNN_model,'save/RNN/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confusion_matrix(CNN_model, x_test, y_test, 'save/CNN/')\n",
    "draw_confusion_matrix(RNN_model, x_test, y_test, 'save/RNN/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_graph(CNN_loss_values, CNN_loss_values_v)\n",
    "plot_loss_graph(RNN_loss_values, RNN_loss_values_v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-job",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

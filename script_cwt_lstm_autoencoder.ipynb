{"cells":[{"cell_type":"markdown","metadata":{},"source":["### CWT 변환 후 LSTM - AutoEncoder 활용"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import random\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import classification_report, confusion_matrix\n","from scipy.fft import fft, ifft\n","import pywt\n","import os\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["### Data Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["- 5000hz, 3000RPM\n","- 변환 후 5000hz_cwt_data/3000rpm"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["RPM = 3000\n","base_path = \"5000hz_raw_data/\" + str(RPM) + \"rpm/\"\n","folders = [\n","    str(RPM) + \"rpm \" + \"normal data\",\n","    str(RPM) + \"rpm \" + \"carriage damage\",\n","    str(RPM) + \"rpm \" + \"high-speed damage\",\n","    str(RPM) + \"rpm \" + \"lack of lubrication\",\n","    str(RPM) + \"rpm \" + \"oxidation and corrosion\",\n","]\n","columns = [\"motor1_x\", \"motor1_y\", \"motor1_z\", \"sound\",\"time\"]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# 데이터를 읽고 결합하는 함수\n","def read_and_concatenate(folder):\n","    all_files = []\n","    for file_name in os.listdir(folder):\n","        if file_name.endswith(\".csv\"):\n","            file_path = os.path.join(folder, file_name)\n","            df = pd.read_csv(file_path, usecols=columns)\n","            all_files.append(df)\n","            break # TEST 용으로 한개만 읽어옴\n","    combined_df = pd.concat(all_files)\n","    combined_df.sort_values(\"time\", inplace=True)  # 시간 열 기준 정렬\n","    return combined_df"]},{"cell_type":"markdown","metadata":{},"source":["### CWT 변환"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# CWT를 적용하는 함수\n","def apply_cwt(data, scales, wavelet_name=\"morl\"):\n","    coefficients, frequencies = pywt.cwt(data, scales, wavelet_name)\n","    return coefficients"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# CWT 이미지 해석\n","def plot_cwt(cwt_matrix, time_segment, axis_label, output_dir = \"cwt_image\"):\n","    plt.figure(figsize=(10, 4))\n","    plt.imshow(\n","        np.abs(cwt_matrix),\n","        extent=[0, 1, 1, len(cwt_matrix)],\n","        cmap=\"viridis\",\n","        aspect=\"auto\",\n","        interpolation=\"bilinear\",\n","    )\n","    plt.colorbar(label=\"Magnitude\")\n","    plt.title(f\"CWT Magnitude for {axis_label} Axis ({time_segment}s Segment)\")\n","    plt.xlabel(\"Time\")\n","    plt.ylabel(\"Frequency (Scale)\")\n","    plt.grid(False)\n","    plt.savefig(f\"{output_dir}/{axis_label}_{time_segment}.png\")\n","    plt.close()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# CWT 이미지로 변환\n","OUTPUT_DIR = \"5000hz_cwt_data/\" + str(RPM) + \"rpm/\"\n","def process_and_save_cwt_images(\n","    df, folder_name, sampling_rate=5000, segment_length=10, scales=np.arange(1, 129)\n","):\n","    # Calculate the number of rows for each segment\n","    num_rows = sampling_rate * segment_length  # 10 seconds of data\n","\n","    # Calculate the total number of segments\n","    time_segments = len(df) // num_rows\n","\n","    # Loop over each segment\n","    for index in range(time_segments):\n","        # Calculate the start and end index for each segment\n","        start_idx = index * num_rows\n","        end_idx = start_idx + num_rows\n","\n","        # Calculate the time segment in seconds\n","        time_segment = (start_idx / sampling_rate, end_idx / sampling_rate)\n","\n","        # Extract the x and y data for the current segment\n","        segment_x = df.iloc[start_idx:end_idx][\"motor1_x\"]\n","        segment_y = df.iloc[start_idx:end_idx][\"motor1_y\"]\n","        segment_z = df.iloc[start_idx:end_idx][\"motor1_z\"]\n","        segment_sound = df.iloc[start_idx:end_idx][\"sound\"]\n","\n","        # Apply the Continuous Wavelet Transform (CWT) to the x and y data\n","        cwtmatr_x = apply_cwt(segment_x, scales)\n","        cwtmatr_y = apply_cwt(segment_y, scales)\n","        cwtmatr_z = apply_cwt(segment_z, scales)\n","        cwtmatr_sound = apply_cwt(segment_sound, scales)\n","\n","        # Plot and save the CWT results\n","        plot_cwt(cwtmatr_x, time_segment, \"X\", OUTPUT_DIR + folder_name)\n","        plot_cwt(cwtmatr_y, time_segment, \"Y\", OUTPUT_DIR + folder_name)\n","        plot_cwt(cwtmatr_z, time_segment, \"Z\", OUTPUT_DIR + folder_name)\n","        plot_cwt(cwtmatr_sound, time_segment, \"S\", OUTPUT_DIR + folder_name)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# 시각화 함수 수정\n","def visualize_cwt(coefficients, sensor_index, scales):\n","    plt.figure(figsize=(10, 4))\n","    plt.imshow(\n","        np.abs(coefficients[sensor_index]),\n","        extent=[0, len(coefficients[sensor_index][0]), scales[-1], scales[0]],\n","        aspect=\"auto\",\n","        cmap=\"viridis\",\n","    )\n","    plt.yscale(\"log\")\n","    plt.colorbar(label=\"Magnitude\")\n","    plt.title(f\"Continuous Wavelet Transform (CWT) - Sensor {sensor_index + 1}\")\n","    plt.ylabel(\"Scale\")\n","    plt.xlabel(\"Time\")\n","    plt.show()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["concatenated_df = dict()\n","folder_index = [\n","    \"normal data\",\n","    \"carriage damage\",\n","   \"high-speed damage\",\n","    \"lack of lubrication\",\n","    \"oxidation and corrosion\",\n","]\n","# 각 폴더에서 데이터를 처리\n","for index,folder_name in enumerate(folders):\n","    folder_path = os.path.join(base_path, folder_name)\n","    concatenated_df[folder_index[index]] = read_and_concatenate(folder_path)\n","\n","    # time 열 제거\n","    concatenated_df[folder_index[index]].drop(columns=\"time\", inplace=True)\n","    # Label 열 추가\n","    concatenated_df[folder_index[index]][\"label\"] = index\n","\n","\n","# # 데이터 결합\n","combined_data = pd.concat(\n","    [\n","        concatenated_df[folder_index[0]],\n","        concatenated_df[folder_index[1]],\n","        concatenated_df[folder_index[2]],\n","        concatenated_df[folder_index[3]],\n","        concatenated_df[folder_index[4]],\n","    ],\n","    ignore_index=True,\n",")\n","features = combined_data[[\"motor1_x\", \"motor1_y\", \"motor1_z\", \"sound\"]]\n","labels = combined_data[\"label\"]\n","\n","# 데이터 정규화\n","scalser = StandardScaler()\n","X_scaled = scalser.fit_transform(features)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["BATCH_SIZE = 64\n","# 데이터를 훈련 및 테스트 세트로 분할\n","X_train, X_test, y_train, y_test = train_test_split(\n","    features.values, labels.values, test_size=0.2, random_state=42\n",")\n","\n","# 훈련 데이터를 훈련 및 검증 세트로 분할\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_train, y_train, test_size=0.2, random_state=42\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# CWT 변환\n","def apply_cwt_to_dataset(data, scales, wavelet_name=\"morl\"):\n","    cwt_features = []\n","    for feature in data.T:  # Apply CWT on each feature (column) of the dataset\n","        cwt_matrix, _ = pywt.cwt(feature, scales, wavelet_name)\n","        # Normalize the CWT matrix\n","        cwt_matrix = (cwt_matrix - np.mean(cwt_matrix)) / np.std(cwt_matrix)\n","        cwt_features.append(cwt_matrix)\n","    # Stack to form [samples, features, time, CWT_coefficients]\n","    return np.stack(cwt_features, axis=1)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([127, 4, 960000])\n","torch.Size([960000])\n"]}],"source":["# Convert CWT\n","scales = np.arange(1, 128)\n","X_train_cwt = apply_cwt_to_dataset(X_train, scales)\n","X_val_cwt = apply_cwt_to_dataset(X_val, scales)\n","X_test_cwt = apply_cwt_to_dataset(X_test, scales)\n","\n","# Convert to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train_cwt, dtype=torch.float32)\n","X_val_tensor = torch.tensor(X_val_cwt, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_cwt, dtype=torch.float32)\n","\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","print(\n","    X_train_tensor.shape\n",")  # Expected to be (number of samples, features, CWT coefficients)\n","print(y_train_tensor.shape)  # Expected to be (number of samples,)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# PyTorch의 Dataset 및 DataLoader 생성\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["### LSTM 모델 구현"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# LSTM 오토인코더 모델 정의\n","class LSTMEncoder(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super(LSTMEncoder, self).__init__()\n","        self.encoder_lstm = nn.LSTM(\n","            input_size, hidden_size, num_layers, batch_first=True\n","        )\n","        self.decoder_lstm = nn.LSTM(\n","            hidden_size, input_size, num_layers, batch_first=True\n","        )\n","\n","    def forward(self, x):\n","        encoded_output, _ = self.encoder_lstm(x)\n","        decoded_output, _ = self.decoder_lstm(encoded_output)\n","        return decoded_output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Hyperparameters\n","input_size = X_train.shape[2] # [\"motor1_x\", \"motor1_y\", \"motor1_z\", \"sound\"]\n","hidden_size = 128\n","num_layers = 2\n","learning_rate = 0.001\n","num_epochs = 100"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 모델 초기화\n","model = LSTMEncoder(input_size, hidden_size, num_layers)\n","\n","# Loss function 및 optimizer 정의\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 체크포인트 파일 경로 설정\n","checkpoint_path = \"./checkpoint/cwt_lstm_autoencoder/model_checkpoint\"\n","\n","# 모델 학습\n","best_val_loss = float(\"inf\")\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    for batch_x, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n","        optimizer.zero_grad()\n","        output = model(batch_x)\n","        loss = criterion(output, batch_x)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * batch_x.size(0)\n","\n","        # 정확도 계산\n","        _, predicted = torch.max(output, 1)\n","        total_train += batch_y.size(0)\n","        correct_train += (predicted == batch_y).sum().item()\n","\n","    # Train Loss & Accuracy 계산\n","    train_loss /= len(train_loader.dataset)\n","    train_accuracy = correct_train / total_train\n","\n","    # 검증 세트로 모델 평가\n","    model.eval()\n","    val_loss = 0.0\n","    correct_val = 0\n","    total_val = 0\n","    with torch.no_grad():\n","        for batch_x, batch_y in val_loader:\n","            output = model(batch_x)\n","            loss = criterion(output, batch_x)\n","            val_loss += loss.item() * batch_x.size(0)\n","\n","            # 정확도 계산\n","            _, predicted = torch.max(output, 1)\n","            total_val += batch_y.size(0)\n","            correct_val += (predicted == batch_y).sum().item()\n","\n","    # Validation Loss & Accuracy 계산\n","    val_loss /= len(val_loader.dataset)\n","    val_accuracy = correct_val / total_val\n","\n","    # 모델의 체크포인트 저장\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        # 체크포인트 저장\n","        torch.save(model.state_dict(), checkpoint_path+str(epoch)+\".pth\")\n","        print(\"Checkpoint saved.\")\n","\n","    if (epoch + 1) % 1 == 0:\n","        print(\n","            f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\"\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 체크포인트 불러오기\n","model.load_state_dict(torch.load(checkpoint_path))\n","\n","model.eval()\n","test_loss = 0.0\n","correct_test = 0\n","total_test = 0\n","with torch.no_grad():\n","    for batch_x, batch_y in tqdm(test_loader, desc=\"Testing\"):\n","        output = model(batch_x)\n","        loss = criterion(output, batch_x)\n","        test_loss += loss.item() * batch_x.size(0)\n","\n","        # 정확도 계산\n","        _, predicted = torch.max(output, 1)\n","        total_test += batch_y.size(0)\n","        correct_test += (predicted == batch_y).sum().item()\n","\n","# Test Loss & Accuracy 계산\n","test_loss /= len(test_loader.dataset)\n","test_accuracy = correct_test / total_test\n","\n","print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"]}],"metadata":{"kernelspec":{"display_name":"ml-job","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":2}

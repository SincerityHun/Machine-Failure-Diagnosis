{"cells":[{"cell_type":"markdown","metadata":{},"source":["### CWT 변환 후 LSTM - AutoEncoder 활용"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import random\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import classification_report, confusion_matrix\n","from scipy.fft import fft, ifft\n","import pywt\n","import os\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["### Data Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["- 5000hz, 3000RPM\n","- 변환 후 5000hz_cwt_data/3000rpm"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["RPM = 3000\n","base_path = \"5000hz_raw_data/\" + str(RPM) + \"rpm/\"\n","folders = [\n","    str(RPM) + \"rpm \" + \"normal data\",\n","    str(RPM) + \"rpm \" + \"carriage damage\",\n","    str(RPM) + \"rpm \" + \"high-speed damage\",\n","    str(RPM) + \"rpm \" + \"lack of lubrication\",\n","    str(RPM) + \"rpm \" + \"oxidation and corrosion\",\n","]\n","columns = [\"motor1_x\", \"motor1_y\", \"motor1_z\", \"sound\",\"time\"]"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# 데이터를 읽고 결합하는 함수\n","def read_and_concatenate(folder):\n","    all_files = []\n","    for file_name in os.listdir(folder):\n","        if file_name.endswith(\".csv\"):\n","            file_path = os.path.join(folder, file_name)\n","            df = pd.read_csv(file_path, usecols=columns)\n","            all_files.append(df)\n","            break # 1개의 파일만 읽도록 수정\n","    combined_df = pd.concat(all_files)\n","    combined_df.sort_values(\"time\", inplace=True)  # 시간 열 기준 정렬\n","    return combined_df"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# CWT를 적용하는 함수\n","def apply_cwt(data, scales, wavelet_name=\"morl\"):\n","    coefficients, frequencies = pywt.cwt(data, scales, wavelet_name)\n","    return coefficients"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# 시각화 함수 수정\n","def visualize_cwt(coefficients, sensor_index, scales):\n","    plt.figure(figsize=(10, 4))\n","    plt.imshow(\n","        np.abs(coefficients[sensor_index]),\n","        extent=[0, len(coefficients[sensor_index][0]), scales[-1], scales[0]],\n","        aspect=\"auto\",\n","        cmap=\"viridis\",\n","    )\n","    plt.yscale(\"log\")\n","    plt.colorbar(label=\"Magnitude\")\n","    plt.title(f\"Continuous Wavelet Transform (CWT) - Sensor {sensor_index + 1}\")\n","    plt.ylabel(\"Scale\")\n","    plt.xlabel(\"Time\")\n","    plt.show()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["concatenated_df = dict()\n","folder_index = [\n","    \"normal data\",\n","    \"carriage damage\",\n","   \"high-speed damage\",\n","    \"lack of lubrication\",\n","    \"oxidation and corrosion\",\n","]\n","# 각 폴더에서 데이터를 처리\n","for index,folder_name in enumerate(folders):\n","    folder_path = os.path.join(base_path, folder_name)\n","    concatenated_df[folder_index[index]] = read_and_concatenate(folder_path)\n","\n","    # time 열 제거\n","    concatenated_df[folder_index[index]].drop(columns=\"time\", inplace=True)\n","    # Label 열 추가\n","    concatenated_df[folder_index[index]][\"label\"] = index\n","\n","# 데이터 결합\n","combined_data = pd.concat(\n","    [\n","        concatenated_df[folder_index[0]],\n","        concatenated_df[folder_index[1]],\n","        concatenated_df[folder_index[2]],\n","        concatenated_df[folder_index[3]],\n","        concatenated_df[folder_index[4]],\n","    ],\n","    ignore_index=True,\n",")\n","features = combined_data[[\"motor1_x\", \"motor1_y\", \"motor1_z\", \"sound\"]]\n","labels = combined_data[\"label\"]\n","\n","# 데이터 정규화\n","scalser = StandardScaler()\n","X_scaled = scalser.fit_transform(features)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["BATCH_SIZE = 64\n","# 데이터를 훈련 및 테스트 세트로 분할\n","X_train, X_test, y_train, y_test = train_test_split(\n","    features.values, labels.values, test_size=0.2, random_state=42\n",")\n","\n","# 훈련 데이터를 훈련 및 검증 세트로 분할\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_train, y_train, test_size=0.2, random_state=42\n",")\n","\n","# 데이터를 PyTorch Tensor로 변환\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","# PyTorch의 Dataset 및 DataLoader 생성\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["### LSTM 모델 구현"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# LSTM 오토인코더 모델 정의\n","class LSTMEncoder(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super(LSTMEncoder, self).__init__()\n","        self.encoder_lstm = nn.LSTM(\n","            input_size, hidden_size, num_layers, batch_first=True\n","        )\n","        self.decoder_lstm = nn.LSTM(\n","            hidden_size, input_size, num_layers, batch_first=True\n","        )\n","\n","    def forward(self, x):\n","        encoded_output, _ = self.encoder_lstm(x)\n","        decoded_output, _ = self.decoder_lstm(encoded_output)\n","        return decoded_output"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# Hyperparameters\n","input_size = X_train.shape[1] # [\"motor1_x\", \"motor1_y\", \"motor1_z\", \"sound\"]\n","hidden_size = 128\n","num_layers = 2\n","learning_rate = 0.001\n","num_epochs = 100"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# 모델 초기화\n","model = LSTMEncoder(input_size, hidden_size, num_layers)\n","\n","# Loss function 및 optimizer 정의\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/100: 100%|██████████| 15000/15000 [10:20<00:00, 24.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Checkpoint saved.\n","Epoch [1/100], Training Loss: 0.2393, Validation Loss: 0.2279, Training Accuracy: 0.1961, Validation Accuracy: 0.2016\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/100: 100%|██████████| 15000/15000 [10:11<00:00, 24.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Checkpoint saved.\n","Epoch [2/100], Training Loss: 0.2310, Validation Loss: 0.2276, Training Accuracy: 0.2075, Validation Accuracy: 0.2051\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/100:  23%|██▎       | 3469/15000 [02:52<1:22:26,  2.33it/s]"]}],"source":["# 체크포인트 파일 경로 설정\n","checkpoint_path = \"./checkpoint/cwt_lstm_autoencoder/model_checkpoint\"\n","\n","# 모델 학습\n","best_val_loss = float(\"inf\")\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    for batch_x, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n","        optimizer.zero_grad()\n","        output = model(batch_x)\n","        loss = criterion(output, batch_x)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * batch_x.size(0)\n","\n","        # 정확도 계산\n","        _, predicted = torch.max(output, 1)\n","        total_train += batch_y.size(0)\n","        correct_train += (predicted == batch_y).sum().item()\n","\n","    # Train Loss & Accuracy 계산\n","    train_loss /= len(train_loader.dataset)\n","    train_accuracy = correct_train / total_train\n","\n","    # 검증 세트로 모델 평가\n","    model.eval()\n","    val_loss = 0.0\n","    correct_val = 0\n","    total_val = 0\n","    with torch.no_grad():\n","        for batch_x, batch_y in val_loader:\n","            output = model(batch_x)\n","            loss = criterion(output, batch_x)\n","            val_loss += loss.item() * batch_x.size(0)\n","\n","            # 정확도 계산\n","            _, predicted = torch.max(output, 1)\n","            total_val += batch_y.size(0)\n","            correct_val += (predicted == batch_y).sum().item()\n","\n","    # Validation Loss & Accuracy 계산\n","    val_loss /= len(val_loader.dataset)\n","    val_accuracy = correct_val / total_val\n","\n","    # 모델의 체크포인트 저장\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        # 체크포인트 저장\n","        torch.save(model.state_dict(), checkpoint_path+str(epoch)+\".pth\")\n","        print(\"Checkpoint saved.\")\n","\n","    if (epoch + 1) % 1 == 0:\n","        print(\n","            f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\"\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 체크포인트 불러오기\n","model.load_state_dict(torch.load(checkpoint_path))\n","\n","model.eval()\n","test_loss = 0.0\n","correct_test = 0\n","total_test = 0\n","with torch.no_grad():\n","    for batch_x, batch_y in tqdm(test_loader, desc=\"Testing\"):\n","        output = model(batch_x)\n","        loss = criterion(output, batch_x)\n","        test_loss += loss.item() * batch_x.size(0)\n","\n","        # 정확도 계산\n","        _, predicted = torch.max(output, 1)\n","        total_test += batch_y.size(0)\n","        correct_test += (predicted == batch_y).sum().item()\n","\n","# Test Loss & Accuracy 계산\n","test_loss /= len(test_loader.dataset)\n","test_accuracy = correct_test / total_test\n","\n","print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"]}],"metadata":{"kernelspec":{"display_name":"ml-job","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":2}
